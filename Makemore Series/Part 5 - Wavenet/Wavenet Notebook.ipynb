{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makermore Part 5 - Wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182778, 8]) torch.Size([182778])\n",
      "torch.Size([22633, 8]) torch.Size([22633])\n",
      "torch.Size([22735, 8]) torch.Size([22735])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> e\n",
      ".......e --> m\n",
      "......em --> m\n",
      ".....emm --> a\n",
      "....emma --> .\n",
      "........ --> o\n",
      ".......o --> l\n",
      "......ol --> i\n",
      ".....oli --> v\n",
      "....oliv --> i\n",
      "...olivi --> a\n",
      "..olivia --> .\n",
      "........ --> a\n",
      ".......a --> v\n",
      "......av --> a\n",
      ".....ava --> .\n",
      "........ --> i\n",
      ".......i --> s\n",
      "......is --> a\n",
      ".....isa --> b\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  def __init__(self, fan_in, fan_out, generator = torch.Generator().manual_seed(2147483647), bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out), generator = generator) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "      \n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  def __init__(self, num_embeddings, embedding_dim, g):\n",
    "    self.weight = torch.rand((num_embeddings, embedding_dim),generator=g)\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Flatten:\n",
    "  def __call__(self, x):\n",
    "    self.out = x.view(x.shape[0], -1)\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "  \n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7081, 0.3542, 0.7081, 0.3542],\n",
       "         [0.7081, 0.3542, 0.7081, 0.3542],\n",
       "         [0.5998, 0.1621, 0.9928, 0.3419],\n",
       "         [0.9600, 0.4388, 0.6008, 0.1163]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.manual_seed(2147483647)\n",
    "n_embd = 2 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 5 # the number of neurons in the hidden layer of the MLP\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd, g),\n",
    "  FlattenConsecutive(2), \n",
    "  # Linear(n_embd * 2, n_hidden, generator=g, bias=False), \n",
    "  # BatchNorm1d(n_hidden), Tanh(),\n",
    "  # FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, generator=g, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  # FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, generator=g, bias=False), \n",
    "  # BatchNorm1d(n_hidden), \n",
    "  # Tanh(),\n",
    "  # Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "# with torch.no_grad():\n",
    "#   model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "  \n",
    "# logits = torch.zeros(7, 27)\n",
    "# for i in range(7):\n",
    "#   logits[i] = model(Xtr[[5+i]])\n",
    "\n",
    "x = model(Xtr[[9]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 100000: 3.2890\n"
     ]
    }
   ],
   "source": [
    "max_steps = 100000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] \n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) \n",
    "  \n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  lr = 0.1 if i < 150000 else 0.01 \n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  if i % 10000 == 0: \n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'die' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdie\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'die' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21432514400>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.8586403131484985\n",
      "val 2.2829551696777344\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudreeno.\n",
      "leiton.\n",
      "dani.\n",
      "kenigaa.\n",
      "keylah.\n",
      "milayana.\n",
      "evera.\n",
      "juday.\n",
      "mia.\n",
      "rosann.\n",
      "nuria.\n",
      "kholana.\n",
      "meyoreth.\n",
      "mahlily.\n",
      "zykeli.\n",
      "jenesia.\n",
      "katalynn.\n",
      "lashlin.\n",
      "damarr.\n",
      "azyia.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> o\n",
      ".......o --> l\n",
      "......ol --> i\n",
      ".....oli --> v\n",
      "....oliv --> i\n",
      "...olivi --> a\n",
      "..olivia --> .\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(Xtr[5:12], Ytr[5:12]):\n",
    "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.zeros(7, 27)\n",
    "for i in range(7):\n",
    "  logits[i] = model(Xtr[[7+i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 64, 2], expected input[1, 1, 1000] to have 64 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m model \u001b[38;5;241m=\u001b[39m WaveNet(num_layers, num_blocks, num_channels, kernel_size)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_signal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[53], line 37\u001b[0m, in \u001b[0;36mWaveNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m skips \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m---> 37\u001b[0m     skip, x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     skips\u001b[38;5;241m.\u001b[39mappend(skip)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# x = torch.sum(torch.stack(skips), dim=0)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# x = torch.relu(self.output_conv1(x))\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# x = self.output_conv2(x)\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[53], line 12\u001b[0m, in \u001b[0;36mWaveNetBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_dilated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_residual(output)\n\u001b[0;32m     14\u001b[0m     skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_skip(output)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pattern_rec\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 64, 2], expected input[1, 1, 1000] to have 64 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WaveNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(WaveNetBlock, self).__init__()\n",
    "        self.conv_dilated = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation, padding=(kernel_size - 1) * dilation // 2)\n",
    "        self.conv_residual = nn.Conv1d(out_channels, out_channels, 1)\n",
    "        self.conv_skip = nn.Conv1d(out_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.tanh(self.conv_dilated(x))\n",
    "        residual = self.conv_residual(output)\n",
    "        skip = self.conv_skip(output)\n",
    "        return (skip, residual + x)\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, num_layers, num_blocks, num_channels, kernel_size):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_channels = num_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # Stack multiple WaveNet blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            WaveNetBlock(num_channels, num_channels, kernel_size, 2 ** i) for _ in range(num_blocks) for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Additional layers for output\n",
    "        self.output_conv1 = nn.Conv1d(num_channels, num_channels, 1)\n",
    "        self.output_conv2 = nn.Conv1d(num_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        for block in self.blocks:\n",
    "            skip, x = block(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        # x = torch.sum(torch.stack(skips), dim=0)\n",
    "        # x = torch.relu(self.output_conv1(x))\n",
    "        # x = self.output_conv2(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "num_layers = 10\n",
    "num_blocks = 1\n",
    "num_channels = 64\n",
    "kernel_size = 2\n",
    "input_length = 1000  # Example input length\n",
    "batch_size = 1\n",
    "\n",
    "# Create a random input signal\n",
    "input_signal = torch.randn(batch_size, 1, input_length)\n",
    "\n",
    "# Create an instance of WaveNet\n",
    "model = WaveNet(num_layers, num_blocks, num_channels, kernel_size)\n",
    "# Forward pass\n",
    "output = model(input_signal)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
