{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.,  1.],\n",
              "         [ 2.,  3.],\n",
              "         [ 4.,  5.]],\n",
              "\n",
              "        [[ 6.,  7.],\n",
              "         [ 8.,  9.],\n",
              "         [10., 11.]],\n",
              "\n",
              "        [[12., 13.],\n",
              "         [14., 15.],\n",
              "         [16., 17.]],\n",
              "\n",
              "        [[18., 19.],\n",
              "         [20., 21.],\n",
              "         [22., 23.]]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B, T, C = 4, 3, 2\n",
        "x = torch.arange(0, B * T * C).view(B,T,C).float()\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000]],\n",
              "\n",
              "        [[-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000]],\n",
              "\n",
              "        [[-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000]],\n",
              "\n",
              "        [[-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000],\n",
              "         [-1.0000,  1.0000]]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer_norm = nn.LayerNorm(normalized_shape=C,elementwise_affine=False,bias=False)\n",
        "layer_norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 2.5000,  8.5000, 14.5000, 20.5000]),\n",
              " tensor([3.5000, 3.5000, 3.5000, 3.5000]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.view(B,T*C).mean(dim=-1),torch.var(x.view(B,T*C),dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1e-05, <generator object Module.parameters at 0x000001B3AA2D5660>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer_norm.eps, layer_norm.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "for parameter in layer_norm.parameters():\n",
        "    print(parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([60.0667, 57.5333, 45.2667, 54.0667]),\n",
              " tensor([ 751.6622,  887.8489, 1344.1956,  561.9289]))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[\n",
        "         [76.,  2., 43.],\n",
        "         [79., 50., 29.],\n",
        "         [59., 78., 73.],\n",
        "         [95., 94., 76.],\n",
        "         [ 9., 74., 64.]],\n",
        "\n",
        "        [[76., 87., 50.],\n",
        "         [ 2., 65., 44.],\n",
        "         [74.,  9., 82.],\n",
        "         [83., 54., 82.],\n",
        "         [ 6., 97., 52.]],\n",
        "\n",
        "        [[88., 19., 95.],\n",
        "         [14., 96., 96.],\n",
        "         [93., 58.,  0.],\n",
        "         [19., 37.,  6.],\n",
        "         [28., 23.,  7.]],\n",
        "\n",
        "        [[ 7., 54., 59.],\n",
        "         [57., 30., 18.],\n",
        "         [88., 89., 63.],\n",
        "         [56., 75., 56.],\n",
        "         [63., 23., 73.]]])\n",
        "\n",
        "B,T,C = x.shape\n",
        "normalized_shape = (T,C)\n",
        "x.view(B,T*C).mean(dim=-1),x.view(B,T*C).var(dim=-1,correction=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "μ = 60.0667\n",
            "σ^2 = 751.6622\n",
            "tensor([[ 0.5812, -2.1179, -0.6225],\n",
            "        [ 0.6906, -0.3672, -1.1331],\n",
            "        [-0.0389,  0.6541,  0.4717],\n",
            "        [ 1.2742,  1.2377,  0.5812],\n",
            "        [-1.8626,  0.5082,  0.1435]])\n",
            "==================================================\n",
            "μ = 57.5333\n",
            "σ^2 = 887.8489\n",
            "tensor([[ 0.6198,  0.9889, -0.2528],\n",
            "        [-1.8637,  0.2506, -0.4542],\n",
            "        [ 0.5526, -1.6288,  0.8211],\n",
            "        [ 0.8547, -0.1186,  0.8211],\n",
            "        [-1.7295,  1.3245, -0.1857]])\n",
            "==================================================\n",
            "μ = 45.2667\n",
            "σ^2 = 1344.1956\n",
            "tensor([[ 1.1656, -0.7164,  1.3565],\n",
            "        [-0.8528,  1.3838,  1.3838],\n",
            "        [ 1.3019,  0.3473, -1.2347],\n",
            "        [-0.7164, -0.2255, -1.0710],\n",
            "        [-0.4710, -0.6073, -1.0437]])\n",
            "==================================================\n",
            "μ = 54.0667\n",
            "σ^2 = 561.9289\n",
            "tensor([[-1.9855, -0.0028,  0.2081],\n",
            "        [ 0.1237, -1.0153, -1.5215],\n",
            "        [ 1.4315,  1.4737,  0.3769],\n",
            "        [ 0.0816,  0.8831,  0.0816],\n",
            "        [ 0.3769, -1.3106,  0.7987]])\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Normalize\n",
        "for i in range(0,4):               # loop through each matrix\n",
        "  mean = x[i].mean()               # mean         \n",
        "  var = x[i].var(unbiased=False)   # variance\n",
        "  layer_norm = (x[i]-mean)/(torch.sqrt(var+0.00005))\n",
        "\n",
        "  print(f\"μ = {mean:.4f}\")            \n",
        "  print(f\"σ^{2} = {var:.4f}\") \n",
        "  print(layer_norm)\n",
        "  print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.5812, -2.1179, -0.6225],\n",
              "         [ 0.6906, -0.3672, -1.1331],\n",
              "         [-0.0389,  0.6541,  0.4717],\n",
              "         [ 1.2742,  1.2377,  0.5812],\n",
              "         [-1.8626,  0.5082,  0.1435]],\n",
              "\n",
              "        [[ 0.6198,  0.9889, -0.2528],\n",
              "         [-1.8637,  0.2506, -0.4542],\n",
              "         [ 0.5526, -1.6288,  0.8211],\n",
              "         [ 0.8547, -0.1186,  0.8211],\n",
              "         [-1.7295,  1.3245, -0.1857]],\n",
              "\n",
              "        [[ 1.1656, -0.7164,  1.3565],\n",
              "         [-0.8528,  1.3838,  1.3838],\n",
              "         [ 1.3019,  0.3473, -1.2347],\n",
              "         [-0.7164, -0.2255, -1.0710],\n",
              "         [-0.4710, -0.6073, -1.0437]],\n",
              "\n",
              "        [[-1.9855, -0.0028,  0.2081],\n",
              "         [ 0.1237, -1.0153, -1.5215],\n",
              "         [ 1.4315,  1.4737,  0.3769],\n",
              "         [ 0.0816,  0.8831,  0.0816],\n",
              "         [ 0.3769, -1.3106,  0.7987]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer_norm = nn.LayerNorm(normalized_shape=normalized_shape,elementwise_affine=True)\n",
        "layer_norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.6752, -0.7385,  1.4137],\n",
              "         [-1.4053,  0.8398,  0.5655],\n",
              "         [ 0.3750, -1.3684,  0.9934],\n",
              "         [-1.4138,  0.7348,  0.6790],\n",
              "         [-1.4073,  0.8243,  0.5830]],\n",
              "\n",
              "        [[ 1.3774, -0.4110, -0.9664],\n",
              "         [-0.8612,  1.4013, -0.5401],\n",
              "         [-1.0923, -0.2318,  1.3241],\n",
              "         [ 1.3485, -1.0432, -0.3053],\n",
              "         [-1.4023,  0.5423,  0.8599]],\n",
              "\n",
              "        [[ 1.4043, -0.8468, -0.5575],\n",
              "         [ 0.3294, -1.3557,  1.0263],\n",
              "         [ 0.1931, -1.3097,  1.1166],\n",
              "         [ 0.1740, -1.3024,  1.1284],\n",
              "         [-1.1555, -0.1283,  1.2838]],\n",
              "\n",
              "        [[ 1.4137, -0.6742, -0.7395],\n",
              "         [-1.4077,  0.5861,  0.8215],\n",
              "         [ 1.3596, -0.3431, -1.0165],\n",
              "         [ 1.4127, -0.6502, -0.7625],\n",
              "         [-1.0251, -0.3312,  1.3563]],\n",
              "\n",
              "        [[-0.8029, -0.6068,  1.4097],\n",
              "         [-0.6944, -0.7198,  1.4141],\n",
              "         [ 0.6351,  0.7767, -1.4118],\n",
              "         [ 1.3668, -0.9979, -0.3689],\n",
              "         [-1.1218, -0.1848,  1.3066]],\n",
              "\n",
              "        [[-0.9878,  1.3704, -0.3826],\n",
              "         [-0.4627, -0.9260,  1.3887],\n",
              "         [-1.3827,  0.4342,  0.9485],\n",
              "         [ 0.2697, -1.3371,  1.0674],\n",
              "         [ 1.2513, -0.0556, -1.1957]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch, sentence_length, embedding_dim = 6, 5, 3\n",
        "torch.manual_seed(0)\n",
        "x = torch.randn(batch, sentence_length, embedding_dim)\n",
        "layer_norm = nn.LayerNorm(embedding_dim)\n",
        "layer_norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.8429,  0.3689, -0.7030, -0.2017,  0.8248],\n",
              "        [-1.0986,  0.6530, -0.0145, -0.0029,  1.0531],\n",
              "        [-0.1703, -0.0709,  0.3976,  0.3771,  0.0952],\n",
              "        [-0.2511,  0.4184, -0.1481, -0.0994,  1.8918],\n",
              "        [-0.3152, -0.0669,  0.3075,  0.8099, -0.3368],\n",
              "        [ 1.0425,  0.3961,  0.4103, -0.5229,  0.2552]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.mean(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.1756, 0.3264, 1.0651, 0.5638, 0.2509],\n",
              "        [0.3820, 0.0100, 1.9893, 0.3119, 0.3846],\n",
              "        [0.6322, 0.0968, 0.0474, 0.1355, 0.1109],\n",
              "        [3.2621, 0.6012, 0.0575, 0.2069, 1.2538],\n",
              "        [2.2937, 0.4870, 1.5997, 1.6531, 1.3275],\n",
              "        [0.4303, 0.8099, 1.6396, 0.3399, 0.0222]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.var(dim=-1,correction=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for parameter in layer_norm.parameters():\n",
        "    print(parameter)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
