{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nn.LSTM output tensor([[[0.0865, 0.0915]]], grad_fn=<StackBackward0>) \n",
            "Manual output tensor([[0.0865, 0.0915]], grad_fn=<MulBackward0>) \n",
            " \n",
            " \n",
            "nn.LSTM hidden tensor([[[0.0865, 0.0915]]], grad_fn=<StackBackward0>)\n",
            "Manual hidden tensor([[0.0865, 0.0915]], grad_fn=<MulBackward0>)\n",
            " \n",
            " \n",
            "nn.LSTM state tensor([[[0.0918, 0.9998]]], grad_fn=<StackBackward0>)\n",
            "manual state tensor([[0.0918, 0.9998]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.0918, 1.0000]], grad_fn=<SigmoidBackward0>) tensor([[1.0000, 0.9998]], grad_fn=<TanhBackward0>) tensor([[0.2151, 0.0219]], grad_fn=<SigmoidBackward0>) tensor([[0.9447, 0.1202]], grad_fn=<SigmoidBackward0>)\n",
            "official:tensor([[[0.0865, 0.0915]]], grad_fn=<StackBackward0>)\n",
            "step:tensor([[0.0865, 0.0915]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "batchsize = 1\n",
        "\n",
        "# nn.LSTM \n",
        "torch.manual_seed(20)\n",
        "lstm_official = torch.nn.LSTM(6, 2, bidirectional=False, num_layers=1, batch_first=False)\n",
        "share_weight = torch.randn(lstm_official .weight_ih_l0.shape,dtype = torch.float)\n",
        "lstm_official.weight_ih_l0 = torch.nn.Parameter(share_weight)\n",
        "# bias set to zeros\n",
        "lstm_official.bias_ih_l0 = torch.nn.Parameter(torch.zeros(lstm_official.bias_ih_l0.shape))\n",
        "lstm_official.weight_hh_l0 = torch.nn.Parameter(torch.ones(lstm_official.weight_hh_l0.shape))\n",
        "# bias set to zeros\n",
        "lstm_official .bias_hh_l0 = torch.nn.Parameter(torch.zeros(lstm_official.bias_ih_l0.shape))\n",
        "x = torch.tensor([[1,2,3,4,5,6],[1,2,3,4,5,6]],dtype=torch.float)\n",
        "lstm_official_out = lstm_official(x[0].unsqueeze(dim=0).unsqueeze(dim=0))\n",
        "\n",
        "# manual implementation\n",
        "W_ii, W_if, W_ig, W_io = lstm_official.weight_ih_l0.split(2, dim=0)\n",
        "b_ii, b_if, b_ig, b_io = lstm_official.bias_ih_l0.split(2, dim=0)\n",
        "\n",
        "W_hi, W_hf, W_hg, W_ho = lstm_official.weight_hh_l0.split(2, dim=0)\n",
        "b_hi, b_hf, b_hg, b_ho = lstm_official.bias_hh_l0.split(2, dim=0)\n",
        "\n",
        "input = x[0].unsqueeze(0)\n",
        "prev_h = torch.zeros((batchsize,2))\n",
        "prev_c = torch.zeros((batchsize,2))\n",
        "\n",
        "i_t = torch.sigmoid(F.linear(input, W_ii, b_ii) + F.linear(prev_h, W_hi, b_hi))\n",
        "f_t = torch.sigmoid(F.linear(input, W_if, b_if) + F.linear(prev_h, W_hf, b_hf))\n",
        "g_t = torch.tanh(F.linear(input, W_ig, b_ig) + F.linear(prev_h, W_hg, b_hg))\n",
        "o_t = torch.sigmoid(F.linear(input, W_io, b_io) + F.linear(prev_h, W_ho, b_ho))\n",
        "c_t = f_t * prev_c + i_t * g_t\n",
        "h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "print('nn.LSTM output {} '.format(lstm_official_out[0]))\n",
        "print('Manual output {} '.format(h_t))\n",
        "print(' ')\n",
        "print(' ')\n",
        "print('nn.LSTM hidden {}'.format(lstm_official_out[1][0]))\n",
        "print('Manual hidden {}'.format(h_t))\n",
        "print(' ')\n",
        "print(' ')\n",
        "print('nn.LSTM state {}'.format(lstm_official_out[1][1]))\n",
        "print('manual state {}'.format( c_t))\n",
        "\n",
        "# implementation step by step\n",
        "out_shape=2\n",
        "batchsize=1\n",
        "i2h = nn.Linear(in_features=6, out_features=8)  #\n",
        "h2h = nn.Linear(in_features=out_shape, out_features=8)\n",
        "i2h.weight = torch.nn.Parameter(share_weight)\n",
        "i2h.bias = torch.nn.Parameter(torch.zeros(i2h.bias.shape))\n",
        "h2h.weight = torch.nn.Parameter(torch.ones(h2h.weight.shape))\n",
        "h2h.bias = torch.nn.Parameter(torch.zeros(h2h.bias.shape))\n",
        "\n",
        "x_i2h = i2h(x[0].unsqueeze(dim=0)) \n",
        "prev_h = torch.zeros((batchsize,2))\n",
        "prev_c = torch.zeros((batchsize,2))\n",
        "x_h2h = h2h(prev_h)\n",
        "gates = x_i2h + x_h2h\n",
        "gates = torch.split(gates,out_shape,-1)\n",
        "in_gate = torch.sigmoid(gates[0])  \n",
        "in_transform = torch.tanh(gates[2])\n",
        "forget_gate = torch.sigmoid(gates[1]) \n",
        "out_gate = torch.sigmoid(gates[3]) \n",
        "print(in_gate,in_transform,forget_gate,out_gate)\n",
        "s0 = forget_gate * prev_c\n",
        "s1 = in_gate * in_transform\n",
        "next_c = s0 + s1\n",
        "next_h = out_gate * F.tanh(next_c)  \n",
        "\n",
        "print(f'official:{lstm_official_out[0]}')\n",
        "print(f'step:{next_h}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 6])\n",
            "torch.Size([8, 2])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "for parameter in lstm_official.parameters():\n",
        "    print(parameter.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
