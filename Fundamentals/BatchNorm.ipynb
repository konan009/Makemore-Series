{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.],\n",
              "          [12., 13., 14., 15.]],\n",
              "\n",
              "         [[16., 17., 18., 19.],\n",
              "          [20., 21., 22., 23.],\n",
              "          [24., 25., 26., 27.],\n",
              "          [28., 29., 30., 31.]],\n",
              "\n",
              "         [[32., 33., 34., 35.],\n",
              "          [36., 37., 38., 39.],\n",
              "          [40., 41., 42., 43.],\n",
              "          [44., 45., 46., 47.]]],\n",
              "\n",
              "\n",
              "        [[[48., 49., 50., 51.],\n",
              "          [52., 53., 54., 55.],\n",
              "          [56., 57., 58., 59.],\n",
              "          [60., 61., 62., 63.]],\n",
              "\n",
              "         [[64., 65., 66., 67.],\n",
              "          [68., 69., 70., 71.],\n",
              "          [72., 73., 74., 75.],\n",
              "          [76., 77., 78., 79.]],\n",
              "\n",
              "         [[80., 81., 82., 83.],\n",
              "          [84., 85., 86., 87.],\n",
              "          [88., 89., 90., 91.],\n",
              "          [92., 93., 94., 95.]]]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B, C, H, W = 2, 3, 4 , 4\n",
        "\n",
        "x = torch.arange(0,B*C*H*W).view(B,C,H,W).float()\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-1.2889, -1.2480, -1.2071, -1.1662],\n",
              "          [-1.1253, -1.0843, -1.0434, -1.0025],\n",
              "          [-0.9616, -0.9207, -0.8798, -0.8388],\n",
              "          [-0.7979, -0.7570, -0.7161, -0.6752]],\n",
              "\n",
              "         [[-1.2889, -1.2480, -1.2071, -1.1662],\n",
              "          [-1.1253, -1.0843, -1.0434, -1.0025],\n",
              "          [-0.9616, -0.9207, -0.8798, -0.8388],\n",
              "          [-0.7979, -0.7570, -0.7161, -0.6752]],\n",
              "\n",
              "         [[-1.2889, -1.2480, -1.2071, -1.1662],\n",
              "          [-1.1253, -1.0843, -1.0434, -1.0025],\n",
              "          [-0.9616, -0.9207, -0.8798, -0.8388],\n",
              "          [-0.7979, -0.7570, -0.7161, -0.6752]]],\n",
              "\n",
              "\n",
              "        [[[ 0.6752,  0.7161,  0.7570,  0.7979],\n",
              "          [ 0.8388,  0.8798,  0.9207,  0.9616],\n",
              "          [ 1.0025,  1.0434,  1.0843,  1.1253],\n",
              "          [ 1.1662,  1.2071,  1.2480,  1.2889]],\n",
              "\n",
              "         [[ 0.6752,  0.7161,  0.7570,  0.7979],\n",
              "          [ 0.8388,  0.8798,  0.9207,  0.9616],\n",
              "          [ 1.0025,  1.0434,  1.0843,  1.1253],\n",
              "          [ 1.1662,  1.2071,  1.2480,  1.2889]],\n",
              "\n",
              "         [[ 0.6752,  0.7161,  0.7570,  0.7979],\n",
              "          [ 0.8388,  0.8798,  0.9207,  0.9616],\n",
              "          [ 1.0025,  1.0434,  1.0843,  1.1253],\n",
              "          [ 1.1662,  1.2071,  1.2480,  1.2889]]]],\n",
              "       grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batchnorm = nn.BatchNorm2d(C)\n",
        "batchnorm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([3.1500, 4.7500, 6.3500]), tensor([62.5516, 62.5516, 62.5516]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batchnorm.running_mean, batchnorm.running_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([1., 1., 1.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0.], requires_grad=True))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batchnorm.weight,batchnorm.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1e-05"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batchnorm.eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[22.6667, 22.6667, 22.6667],\n",
              "        [22.6667, 22.6667, 22.6667]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.view(B, C, H* W ).var(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7.5000, 23.5000, 39.5000],\n",
              "        [55.5000, 71.5000, 87.5000]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.view(B, C, H* W ).mean(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[170.6667, 170.6667, 170.6667, 170.6667],\n",
              "         [170.6667, 170.6667, 170.6667, 170.6667],\n",
              "         [170.6667, 170.6667, 170.6667, 170.6667],\n",
              "         [170.6667, 170.6667, 170.6667, 170.6667]],\n",
              "\n",
              "        [[170.6667, 170.6667, 170.6667, 170.6667],\n",
              "         [170.6667, 170.6667, 170.6667, 170.6667],\n",
              "         [170.6667, 170.6667, 170.6667, 170.6667],\n",
              "         [170.6667, 170.6667, 170.6667, 170.6667]]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.var(correction=False,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[16., 17., 18., 19.],\n",
              "         [20., 21., 22., 23.],\n",
              "         [24., 25., 26., 27.],\n",
              "         [28., 29., 30., 31.]],\n",
              "\n",
              "        [[64., 65., 66., 67.],\n",
              "         [68., 69., 70., 71.],\n",
              "         [72., 73., 74., 75.],\n",
              "         [76., 77., 78., 79.]]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.5256, -0.7502, -0.6540],\n",
              "        [-1.6095, -0.1002, -0.6092]])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "norm = nn.BatchNorm2d(3,momentum=0.10)\n",
        "d = torch.randn(2, 3, 2, 3)\n",
        "d[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(-0.3690), tensor(0.4563))"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "var = torch.split(d, 1, dim=1)[0].var(correction=False)\n",
        "mean = torch.split(d, 1, dim=1)[0].mean()\n",
        "mean,var\n",
        "# (d[0][0][0][0] - mean) * ( var - 0.00005)**-0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-1.7121, -0.5643, -0.4219], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = norm(d)\n",
        "d[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(-0.0369), tensor(0.0456))"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "running_mean = (1 - norm.momentum) * 0 + norm.momentum * mean\n",
        "running_var = (1 - norm.momentum) * 0 + norm.momentum * var\n",
        "running_mean, running_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(-0.0369), tensor(0.9498))"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "norm.running_mean[0], norm.running_var[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-1.7189, -0.5412, -0.3950], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "norm.training = False\n",
        "d = norm(d)\n",
        "d[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-1.7434, -0.4675, -0.3091], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = norm(d)\n",
        "d[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1.3790,  2.5286,  0.4107, -0.9880],\n",
            "        [-0.9081,  0.5423,  0.1103, -2.2590]])\n",
            "Output tensor after manual BatchNorm: tensor([[ 1.0000,  1.0000,  0.9998,  1.0000],\n",
            "        [-1.0000, -1.0000, -0.9998, -1.0000]], grad_fn=<AddBackward0>)\n",
            "Output tensor after manual BatchNorm: tensor([[ 1.0000,  1.0000,  0.9998,  1.0000],\n",
            "        [-1.0000, -1.0000, -0.9998, -1.0000]],\n",
            "       grad_fn=<NativeBatchNormBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class ManualBatchNorm1d(torch.nn.Module):\n",
        "    def __init__(self, num_features, momentum=0.1, eps=1e-5):\n",
        "        super(ManualBatchNorm1d, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.momentum = momentum\n",
        "        self.eps = eps\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.weight = torch.nn.Parameter(torch.ones(num_features))\n",
        "        self.bias = torch.nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "        # Initialize running mean and variance\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "        self.register_buffer('running_var', torch.ones(num_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            # Compute mean and variance over the batch dimension\n",
        "            batch_mean = x.mean(dim=0)\n",
        "            batch_var = x.var(dim=0, unbiased=False)\n",
        "\n",
        "            # Update running mean and variance with momentum\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * batch_mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * batch_var\n",
        "\n",
        "            # Normalize input using batch statistics\n",
        "            x_normalized = (x - batch_mean) / torch.sqrt(batch_var + self.eps)\n",
        "        else:\n",
        "            # Normalize input using running statistics\n",
        "            x_normalized = (x - self.running_mean) / torch.sqrt(self.running_var + self.eps)\n",
        "\n",
        "        # Scale and shift normalized input\n",
        "        return x_normalized * self.weight + self.bias\n",
        "\n",
        "\n",
        "# Create a manual BatchNorm layer\n",
        "num_features = 4\n",
        "batchnorm = ManualBatchNorm1d(num_features)\n",
        "batchnorm2 = nn.BatchNorm1d(num_features)\n",
        "\n",
        "# Create a tensor of shape (batch_size, num_features)\n",
        "batch_size = 2\n",
        "input_tensor = torch.randn(batch_size, num_features)\n",
        "print(input_tensor)\n",
        "\n",
        "# Forward pass through the manual BatchNorm layer\n",
        "output_tensor = batchnorm(input_tensor)\n",
        "output_tensor1 = batchnorm2(input_tensor)\n",
        "\n",
        "print(\"Output tensor after manual BatchNorm:\", output_tensor)\n",
        "print(\"Output tensor after manual BatchNorm:\", output_tensor1)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
